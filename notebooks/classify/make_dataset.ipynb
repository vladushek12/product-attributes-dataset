{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ff65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41536d2",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796cec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_INDEX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3504f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851e5034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83755"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"..\\\\..\\\\src\\\\data\\\\komus\\\\dataset.json\"\n",
    "\n",
    "with open(PATH, \"r\", encoding=\"UTF-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES_PATH = \".\\\\categories.txt\"\n",
    "\n",
    "with open(CATEGORIES_PATH, \"r\", encoding=\"UTF-8\") as file:\n",
    "    categories_array = file.read().splitlines()\n",
    "\n",
    "categories_txt = \"\\n\".join([f\"{i}. {category}\" for i, category in enumerate(categories_array, start=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f02c3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4125775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "T_PRO_CREDS = \"..\\\\..\\\\secrets\\\\t-pro.json\"\n",
    "\n",
    "with open(T_PRO_CREDS) as file:\n",
    "    model_params = json.load(file)\n",
    "\n",
    "llm = ChatOpenAI(**model_params, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014276a0",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42213bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, **kwargs):\n",
    "    \"\"\"\n",
    "    Преобразует массив словарей, оставляя только нужные ключи.\n",
    "\n",
    "    :param data: Исходный массив словарей.\n",
    "    :return: Новый массив словарей с преобразованными данными.\n",
    "    \"\"\"\n",
    "    transformed_data = []\n",
    "    for item in data:\n",
    "        new_item = {\n",
    "            \"categories\": categories_txt,\n",
    "            \"format_instructions\": kwargs[\"format_instructions\"],\n",
    "            \"problem_title\": item.get(\"title\", None),\n",
    "            \"problem_categories\": item[\"category\"]\n",
    "        }\n",
    "        transformed_data.append(new_item)\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1ee43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для создания батчей\n",
    "def create_batches(array, batch_size, start_index=0):\n",
    "    \"\"\"\n",
    "    Разделяет массив на батчи заданного размера, начиная с указанного индекса.\n",
    "\n",
    "    :param array: Исходный массив (список).\n",
    "    :param batch_size: Размер одного батча.\n",
    "    :param start_index: Индекс, с которого начинать создание батчей.\n",
    "    :return: Список батчей (списков).\n",
    "    \"\"\"\n",
    "    if batch_size <= 0:\n",
    "        raise ValueError(\"Размер батча должен быть больше 0.\")\n",
    "    # Обрезаем массив, начиная с start_index\n",
    "    array = array[start_index:]\n",
    "    batches = [array[i:i + batch_size] for i in range(0, len(array), batch_size)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_prompts(system_prompt: str, user_prompt: str) -> ChatPromptTemplate:\n",
    "    \"\"\"\n",
    "    Создает шаблон промпта для модели.\n",
    "\n",
    "    :param system_prompt: Системный промпт.\n",
    "    :param user_prompt: Пользовательский промпт.\n",
    "    :return: Шаблон промпта.\n",
    "    \"\"\"\n",
    "    system_prompt_template = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    user_prompt_template = HumanMessagePromptTemplate.from_template(user_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_prompt_template, user_prompt_template])\n",
    "    return chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ecfbb",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93fab523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyResponse(BaseModel):\n",
    "    category: str = Field(..., description=\"\"\"Ответ в формате: КАТЕГОРИЯ\"\"\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ClassifyResponse)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Ты — эксперт в классификации товаров. Твоя задача — определить категорию товара на основе его названия и вложенных категорий. Используй следующие категории:\n",
    "\n",
    "{categories}\n",
    "\n",
    "Правила классификации:  \n",
    "- Внимательно анализируй название товара.  \n",
    "- Если название явно указывает на категорию, выбери соответствующую.  \n",
    "- Если категория не очевидна, выбери наиболее подходящую из предложенных.\n",
    "- Если в названии товарной позиции описывается действие, то это должна быть категория \"Услуги\"\n",
    "- ПО считается услугой\n",
    "\n",
    "\n",
    "Правила для формирования ответа:\n",
    "1. **Финальный ответ должен быть представлен в виде JSON-объекта, заключённого в один блок кода.**  \n",
    "   - Финальный ответ должен быть корректным JSON-объектом, который заключается в один блок кода (используя три обратных апострофа ```).\n",
    "   - Внутри JSON-объекта не должно быть дополнительных объяснений или текстовых комментариев.\n",
    "2. **Фраза \"Окончательный ответ\" должна предварять блок кода с JSON-объектом.**  \n",
    "   - Перед блоком кода с JSON-объектом должна быть написана фраза **\"Окончательный ответ:\"** (без кавычек в самой фразе).  \n",
    "   - Между фразой и блоком кода не должно быть пустых строк.\n",
    "\n",
    "Формат ответа должен соответствовать этому: {format_instructions}\n",
    "\"\"\".strip()\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Товарная позиция: {problem_title}\n",
    "Вложенные категории: {problem_categories}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = create_model_prompts(SYSTEM_PROMPT, USER_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd1ccd",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b935b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transform_data(data, format_instructions=parser.get_format_instructions())\n",
    "\n",
    "batches = create_batches(transformed_data, batch_size=100, start_index=START_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c179cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir\n",
    "\n",
    "mkdir(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa4dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(item, parser, categories_array):\n",
    "    if \"Окончательный ответ:\" not in item.content:\n",
    "        return \"\"\n",
    "    content_part = item.content.split(\"Окончательный ответ:\")[1]\n",
    "    parsed = parser.invoke(content_part)\n",
    "    return parsed.category if parsed.category in categories_array else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb194b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: .\\dataset\\batch_0.json\n",
      "Save: .\\dataset\\batch_1.json\n",
      "Save: .\\dataset\\batch_2.json\n",
      "Save: .\\dataset\\batch_3.json\n",
      "Save: .\\dataset\\batch_4.json\n",
      "Save: .\\dataset\\batch_5.json\n",
      "Save: .\\dataset\\batch_6.json\n",
      "Save: .\\dataset\\batch_7.json\n",
      "Save: .\\dataset\\batch_8.json\n",
      "Save: .\\dataset\\batch_9.json\n",
      "Save: .\\dataset\\batch_10.json\n",
      "Save: .\\dataset\\batch_11.json\n",
      "Save: .\\dataset\\batch_12.json\n",
      "Save: .\\dataset\\batch_13.json\n",
      "Save: .\\dataset\\batch_14.json\n",
      "Save: .\\dataset\\batch_15.json\n",
      "Save: .\\dataset\\batch_16.json\n",
      "Save: .\\dataset\\batch_17.json\n",
      "Save: .\\dataset\\batch_18.json\n",
      "Save: .\\dataset\\batch_19.json\n",
      "Save: .\\dataset\\batch_20.json\n",
      "Save: .\\dataset\\batch_21.json\n",
      "Save: .\\dataset\\batch_22.json\n",
      "Save: .\\dataset\\batch_23.json\n",
      "Save: .\\dataset\\batch_24.json\n",
      "Save: .\\dataset\\batch_25.json\n",
      "Save: .\\dataset\\batch_26.json\n",
      "Save: .\\dataset\\batch_27.json\n",
      "Save: .\\dataset\\batch_28.json\n",
      "Save: .\\dataset\\batch_29.json\n",
      "Save: .\\dataset\\batch_30.json\n",
      "Save: .\\dataset\\batch_31.json\n",
      "Save: .\\dataset\\batch_32.json\n",
      "Save: .\\dataset\\batch_33.json\n",
      "Save: .\\dataset\\batch_34.json\n",
      "Save: .\\dataset\\batch_35.json\n",
      "Save: .\\dataset\\batch_36.json\n",
      "Save: .\\dataset\\batch_37.json\n",
      "Save: .\\dataset\\batch_38.json\n",
      "Save: .\\dataset\\batch_39.json\n",
      "Save: .\\dataset\\batch_40.json\n",
      "Save: .\\dataset\\batch_41.json\n",
      "Save: .\\dataset\\batch_42.json\n",
      "Save: .\\dataset\\batch_43.json\n",
      "Save: .\\dataset\\batch_44.json\n",
      "Save: .\\dataset\\batch_45.json\n",
      "Save: .\\dataset\\batch_46.json\n",
      "Save: .\\dataset\\batch_47.json\n",
      "Save: .\\dataset\\batch_48.json\n",
      "Save: .\\dataset\\batch_49.json\n",
      "Save: .\\dataset\\batch_50.json\n",
      "Save: .\\dataset\\batch_51.json\n",
      "Save: .\\dataset\\batch_52.json\n",
      "Save: .\\dataset\\batch_53.json\n",
      "Save: .\\dataset\\batch_54.json\n",
      "Save: .\\dataset\\batch_55.json\n",
      "Save: .\\dataset\\batch_56.json\n",
      "Save: .\\dataset\\batch_57.json\n",
      "Save: .\\dataset\\batch_58.json\n",
      "Save: .\\dataset\\batch_59.json\n",
      "Save: .\\dataset\\batch_60.json\n",
      "Save: .\\dataset\\batch_61.json\n",
      "Save: .\\dataset\\batch_62.json\n",
      "Save: .\\dataset\\batch_63.json\n",
      "Save: .\\dataset\\batch_64.json\n",
      "Save: .\\dataset\\batch_65.json\n",
      "Save: .\\dataset\\batch_66.json\n",
      "Save: .\\dataset\\batch_67.json\n",
      "Save: .\\dataset\\batch_68.json\n",
      "Save: .\\dataset\\batch_69.json\n",
      "Save: .\\dataset\\batch_70.json\n",
      "Save: .\\dataset\\batch_71.json\n",
      "Save: .\\dataset\\batch_72.json\n",
      "Save: .\\dataset\\batch_73.json\n",
      "Save: .\\dataset\\batch_74.json\n",
      "Save: .\\dataset\\batch_75.json\n",
      "Save: .\\dataset\\batch_76.json\n",
      "Save: .\\dataset\\batch_77.json\n",
      "Save: .\\dataset\\batch_78.json\n",
      "Save: .\\dataset\\batch_79.json\n",
      "Save: .\\dataset\\batch_80.json\n",
      "Save: .\\dataset\\batch_81.json\n",
      "Save: .\\dataset\\batch_82.json\n",
      "Save: .\\dataset\\batch_83.json\n",
      "Save: .\\dataset\\batch_84.json\n",
      "Save: .\\dataset\\batch_85.json\n",
      "Save: .\\dataset\\batch_86.json\n",
      "Save: .\\dataset\\batch_87.json\n",
      "Save: .\\dataset\\batch_88.json\n",
      "Save: .\\dataset\\batch_89.json\n",
      "Save: .\\dataset\\batch_90.json\n",
      "Save: .\\dataset\\batch_91.json\n",
      "Save: .\\dataset\\batch_92.json\n",
      "Save: .\\dataset\\batch_93.json\n",
      "Save: .\\dataset\\batch_94.json\n",
      "Save: .\\dataset\\batch_95.json\n",
      "Save: .\\dataset\\batch_96.json\n",
      "Save: .\\dataset\\batch_97.json\n",
      "Save: .\\dataset\\batch_98.json\n",
      "Save: .\\dataset\\batch_99.json\n",
      "Save: .\\dataset\\batch_100.json\n",
      "Save: .\\dataset\\batch_101.json\n",
      "Save: .\\dataset\\batch_102.json\n",
      "Save: .\\dataset\\batch_103.json\n",
      "Save: .\\dataset\\batch_104.json\n",
      "Save: .\\dataset\\batch_105.json\n",
      "Save: .\\dataset\\batch_106.json\n",
      "Save: .\\dataset\\batch_107.json\n",
      "Save: .\\dataset\\batch_108.json\n",
      "Save: .\\dataset\\batch_109.json\n",
      "Save: .\\dataset\\batch_110.json\n",
      "Save: .\\dataset\\batch_111.json\n",
      "Save: .\\dataset\\batch_112.json\n",
      "Save: .\\dataset\\batch_113.json\n",
      "Save: .\\dataset\\batch_114.json\n",
      "Save: .\\dataset\\batch_115.json\n",
      "Save: .\\dataset\\batch_116.json\n",
      "Save: .\\dataset\\batch_117.json\n",
      "Save: .\\dataset\\batch_118.json\n",
      "Save: .\\dataset\\batch_119.json\n",
      "Save: .\\dataset\\batch_120.json\n",
      "Save: .\\dataset\\batch_121.json\n",
      "Save: .\\dataset\\batch_122.json\n",
      "Save: .\\dataset\\batch_123.json\n",
      "Save: .\\dataset\\batch_124.json\n",
      "Save: .\\dataset\\batch_125.json\n",
      "Save: .\\dataset\\batch_126.json\n",
      "Save: .\\dataset\\batch_127.json\n",
      "Save: .\\dataset\\batch_128.json\n",
      "Save: .\\dataset\\batch_129.json\n",
      "Save: .\\dataset\\batch_130.json\n",
      "Save: .\\dataset\\batch_131.json\n",
      "Save: .\\dataset\\batch_132.json\n",
      "Save: .\\dataset\\batch_133.json\n",
      "Save: .\\dataset\\batch_134.json\n",
      "Save: .\\dataset\\batch_135.json\n",
      "Save: .\\dataset\\batch_136.json\n",
      "Save: .\\dataset\\batch_137.json\n",
      "Save: .\\dataset\\batch_138.json\n",
      "Save: .\\dataset\\batch_139.json\n",
      "Save: .\\dataset\\batch_140.json\n",
      "Save: .\\dataset\\batch_141.json\n",
      "Save: .\\dataset\\batch_142.json\n",
      "Save: .\\dataset\\batch_143.json\n",
      "Save: .\\dataset\\batch_144.json\n",
      "Save: .\\dataset\\batch_145.json\n",
      "Save: .\\dataset\\batch_146.json\n",
      "Save: .\\dataset\\batch_147.json\n",
      "Save: .\\dataset\\batch_148.json\n",
      "Save: .\\dataset\\batch_149.json\n",
      "Save: .\\dataset\\batch_150.json\n",
      "Save: .\\dataset\\batch_151.json\n",
      "Save: .\\dataset\\batch_152.json\n",
      "Save: .\\dataset\\batch_153.json\n",
      "Save: .\\dataset\\batch_154.json\n",
      "Save: .\\dataset\\batch_155.json\n",
      "Save: .\\dataset\\batch_156.json\n",
      "Save: .\\dataset\\batch_157.json\n",
      "Save: .\\dataset\\batch_158.json\n",
      "Save: .\\dataset\\batch_159.json\n",
      "Save: .\\dataset\\batch_160.json\n",
      "Save: .\\dataset\\batch_161.json\n",
      "Save: .\\dataset\\batch_162.json\n",
      "Save: .\\dataset\\batch_163.json\n",
      "Save: .\\dataset\\batch_164.json\n",
      "Save: .\\dataset\\batch_165.json\n",
      "Save: .\\dataset\\batch_166.json\n",
      "Save: .\\dataset\\batch_167.json\n",
      "Save: .\\dataset\\batch_168.json\n",
      "Save: .\\dataset\\batch_169.json\n",
      "Save: .\\dataset\\batch_170.json\n",
      "Save: .\\dataset\\batch_171.json\n",
      "Save: .\\dataset\\batch_172.json\n",
      "Save: .\\dataset\\batch_173.json\n",
      "Save: .\\dataset\\batch_174.json\n",
      "Save: .\\dataset\\batch_175.json\n",
      "Save: .\\dataset\\batch_176.json\n",
      "Save: .\\dataset\\batch_177.json\n",
      "Save: .\\dataset\\batch_178.json\n",
      "Save: .\\dataset\\batch_179.json\n",
      "Save: .\\dataset\\batch_180.json\n",
      "Save: .\\dataset\\batch_181.json\n",
      "Save: .\\dataset\\batch_182.json\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "for i, batch in enumerate(batches, start=START_INDEX):\n",
    "    results = chain.batch(batch) \n",
    "\n",
    "    parsed_results = [get_category(item, parser, categories_array) for item in results]\n",
    "\n",
    "    dump_data = [{\n",
    "        \"title\": product[\"problem_title\"],\n",
    "        \"categories\": product[\"problem_categories\"],\n",
    "        \"answer\": res\n",
    "    } for product, res in zip(batch, parsed_results)]\n",
    "\n",
    "    with open(f\".\\\\dataset\\\\batch_{i}.json\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        print(f\"Save: {file.name}\")\n",
    "        json.dump(dump_data, file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
