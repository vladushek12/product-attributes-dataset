{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-vertexai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.6)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.56.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-google-vertexai) (1.57.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.17.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-google-vertexai) (2.17.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-google-vertexai) (0.2.23)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (4.25.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.10.18)\n",
      "Requirement already satisfied: docstring-parser<1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (1.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (0.1.75)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (8.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.62.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.13.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-vertexai) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2024.7.4)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_openai\n",
    "!pip install langchain-google-vertexai\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict, Any, List, Callable, Iterable, Tuple\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field, asdict\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from langchain_core.runnables import Runnable, RunnableMap, RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer \n",
    "from langchain_community.vectorstores import FAISS, VectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "PROJECT_ID = 'axial-chemist-425510-p2'\n",
    "LOCATION = \"europe-west4\"\n",
    "\n",
    "# Укажите путь к вашему JSON-файлу с кредами\n",
    "SERVICE_ACCOUNT_FILE = \"../secrets/axial-chemist-425510-p2-b4eb1d622fbe.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = SERVICE_ACCOUNT_FILE\n",
    "\n",
    "\n",
    "llm_params = {\n",
    "    'model_name': 'gemini-2.0-flash-001',\n",
    "    'project': PROJECT_ID,\n",
    "    'location': LOCATION\n",
    "}\n",
    "\n",
    "LS_API_KEY = 'cb4fde840c4404906bbf7848800e03d2b0d5e98f'\n",
    "LABEL_STUDIO_URL = 'https://custom-servers.t1v.scibox.tech/label-studio/30'\n",
    "RAG_DATA_PROJECT_ID = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ParamsJsonFixingParser:\n",
    "    json_input_variables: list = field(default_factory=dict)\n",
    "    json_fixing_template: str = field(default_factory=str)\n",
    "    max_retries: int = field(default_factory=int)\n",
    "    dict = asdict\n",
    "\n",
    "\n",
    "\n",
    "def convert_attrs_string2dict(str_with_attrs: str) -> str:\n",
    "    \"\"\"\n",
    "    ПЕРВОНАЧАЛЬНЫЙ ВАРИАНТ С РЕГУЛЯРКАМИ\n",
    "    Преобразует строку с атрибутами в формате 'attr1: val1, attr2: val2, ...' \n",
    "    в json строку со словарем.\n",
    "    \n",
    "    Args:\n",
    "        str_with_attrs (str): строка в формате 'attr1: val1, attr2: val2, ...'\n",
    "        \n",
    "    Returns:\n",
    "        str: Словарь, в формате json\n",
    "    \"\"\"\n",
    "    attrs_dict = {}\n",
    "    if str_with_attrs:\n",
    "        # Разбиваем по запятым, за которыми следует паттерн \"что-то до двоеточия :\"\n",
    "        parts = re.split(r',\\s*(?=[^:]+:)', str_with_attrs)\n",
    "        for part in parts:\n",
    "            # Теперь на каждой части ищем ключ:значение\n",
    "            match = re.match(r'([^:]+):\\s*(.*)', part)\n",
    "            if match:\n",
    "                key = match.group(1).strip().strip(\"'\").strip('\"')\n",
    "                value = match.group(2).strip().strip(\"'\").strip('\"')\n",
    "                attrs_dict[key] = value\n",
    "    return json.dumps(attrs_dict, ensure_ascii=False, indent=None)\n",
    "\n",
    "\n",
    "def create_model_prompts(system_prompt: str,\n",
    "                         user_prompt: str) -> ChatPromptTemplate:\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    user_prompt = HumanMessagePromptTemplate.from_template(user_prompt)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_prompt,\n",
    "         user_prompt]\n",
    "    )\n",
    "    return chat_prompt\n",
    "\n",
    "def prepare_retriever_results_to_prompt(examples: List[Tuple[float, Dict]],\n",
    "                                        key_name_problem: str = 'page_content',\n",
    "                                        key_name_information: str = 'metadata',\n",
    "                                        string_pattern_per_example: str = 'Name:\\n{problem}\\nExtracted information:\\n{information}\\n',\n",
    "                                        key_name_problem_in_pattern: str = 'problem',\n",
    "                                        key_name_information_in_pattern: str = 'information') -> str:\n",
    "    \"\"\"Подготавливаем строчку с few_shot (в текущем пайплайне используется для подготовки\n",
    "       примеров полученных из vector_store)\n",
    "\n",
    "    Args:\n",
    "        examples (List[Tuple[float, Dict]]): найденные в векторной базе примеры с скорами\n",
    "        key_name_problem (str, optional): ключ в словаре каждого примера, в котором содержится наименование проблемы\n",
    "                                          (в нашем случае строчка с описанием продукта). Defaults to 'page_content'.\n",
    "        key_name_information (str, optional): ключ в словаре каждого примера, в котором содержится пример как надо обрабатать проблему\n",
    "                                              (в нашему случае по ключу содержиться разложение на атрибутный состав). Defaults to 'metadata'.\n",
    "        string_pattern_per_example (str, optional): шаблон того, как будет выглядить каждый пример. В шаблон должна вставляться информация\n",
    "                                                    полученная по `key_name_problem` и информация полученная по `key_name_information`. Defaults to 'Name:\\n{problem}\\nExtracted information:\\n{information}\\n'.\n",
    "        key_name_problem_in_pattern (str, optional): ключ в шаблоне `string_pattern_per_example` куда вставить значение полученное\n",
    "                                                     по `key_name_problem`. Defaults to 'problem'.\n",
    "        key_name_information_in_pattern (str, optional): ключ в шаблоне `string_pattern_per_example` куда вставить значение полученное\n",
    "                                                         по `key_name_information`. Defaults to 'information'.\n",
    "\n",
    "    Returns:\n",
    "        str: подготовленная строка с примерами (в нашем случае полученными при помощи RAG)\n",
    "    \"\"\"\n",
    "    few_shot_prompt_with_nearest_examples: str = ''\n",
    "    for i, (search_sim, example) in enumerate(examples, start=1):\n",
    "        prepared_string_with_example: str = string_pattern_per_example.format(**{\n",
    "            key_name_problem_in_pattern: example[key_name_problem],\n",
    "            key_name_information_in_pattern: example[key_name_information]\n",
    "        })\n",
    "        few_shot_prompt_with_nearest_examples += f'{str(i)}. {prepared_string_with_example}'\n",
    "    if not few_shot_prompt_with_nearest_examples:\n",
    "        few_shot_prompt_with_nearest_examples = 'Without examples'\n",
    "    \n",
    "    return few_shot_prompt_with_nearest_examples\n",
    "\n",
    "\n",
    "def get_vector_store(\n",
    "        texts: Iterable[str] | Iterable[Document],\n",
    "        model_name: str,\n",
    "        model_kwargs: dict = {'device': 'cpu'},\n",
    "        encode_kwargs: dict = {'normalize_embeddings': True},\n",
    "        **kwargs: dict,\n",
    "        ) -> tuple[\n",
    "            VectorStore, \n",
    "            Callable, \n",
    "            Callable\n",
    "            ]:\n",
    "    \"\"\"\n",
    "    Создаем векторное хранилище и возвращаем триплет:\n",
    "    - векторное хранилище\n",
    "    - функция для поиска по векторному хранилищу\n",
    "    - функция для добавления данных в хранилище\n",
    "    При поиске используется similarity_search_with_relevance_score и числом текстов к = 5\n",
    "    \"\"\"\n",
    "    if not isinstance(texts, Iterable):\n",
    "        raise TypeError('texts must be a Iterable!')\n",
    "    elif not all([isinstance(text, str) for text in texts]) \\\n",
    "        and not all([isinstance(doc, Document) for doc in texts]):\n",
    "        raise TypeError('texts must contain only strings or Documents!')\n",
    "\n",
    "    emb_model = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    if isinstance(next(iter(texts)), str):\n",
    "        vectorstore = FAISS.from_texts(\n",
    "            texts, embedding=emb_model, **kwargs\n",
    "        )\n",
    "    else:\n",
    "        vectorstore = FAISS.from_documents(\n",
    "            texts, embedding=emb_model, **kwargs\n",
    "        )\n",
    "\n",
    "    return vectorstore, partial(vectorstore.similarity_search_with_relevance_scores, k=5), vectorstore.add_texts\n",
    "\n",
    "\n",
    "\n",
    "def create_json_fixing_parser(client_parser_init_params: Dict[str, Any],\n",
    "                              json_input_variables: List[str],\n",
    "                              json_fixing_template: str,\n",
    "                              max_retries: int) -> Runnable:\n",
    "    \"\"\"Создает Цепочку с Fixing Output Parser, который пытается извлечь\n",
    "    результаты JSON объекта из строки. Если извлечение не будет произведено,\n",
    "    то вызовется ошибка и мы попросить у другой модели исправить ответ предыдущей таким образом,\n",
    "    чтобы json стал корректным.\n",
    "\n",
    "    Args:\n",
    "        client_parser_init_params (Dict[str, Any]): параметры модели, которой будет отправлен запрос, если результаты парсинга будут отрицательные;\n",
    "        json_input_variables (List[str]): переменные, которые принимает json_input_variables;\n",
    "        json_fixing_template (str): промпт для запроса, который исправляет результаты парсинга json;\n",
    "        max_retries (int): количество попыток исправления;\n",
    "\n",
    "    Returns:\n",
    "        Runnable: Цепочка пытающаяся спарсить ответ другой модели в формате JSON.\n",
    "    \"\"\"\n",
    "    client_parser = ChatVertexAI(**client_parser_init_params)\n",
    "    json_fixing_parser = OutputFixingParser.from_llm(\n",
    "        parser=JsonOutputParser(),\n",
    "        llm=client_parser,\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=json_input_variables,\n",
    "            template=json_fixing_template\n",
    "        ),\n",
    "        max_retries=max_retries\n",
    "    )\n",
    "    return json_fixing_parser\n",
    "\n",
    "\n",
    "def create_chain_with_rag(llm_params: Dict[str, Any],\n",
    "                          system_prompt: str,\n",
    "                          user_prompt: str,\n",
    "                          params_json_fixing_parser: ParamsJsonFixingParser,\n",
    "                          embedding_model: str,\n",
    "                          vectorstore_data: List[Dict[str, Any]],\n",
    "                          k: int = 5,\n",
    "                          score_threshold: float = 0.2) -> Runnable:\n",
    "    \"\"\"Создает лангчейн цепочку с RAG, где в качестве\n",
    "    векторной базы используется FAISS.\n",
    "\n",
    "    Args:\n",
    "        llm_params (Dict[str, Any]): параметры для инициализации клиента ChatOpenAI;\n",
    "        system_prompt (str): системный промпт использующий примеры полученные из vector_store;\n",
    "        user_prompt (str): пользовательский промпт, куда вставляется описание товара;\n",
    "        params_json_fixing_parser (ParamsJsonFixingParser): параметры для инициализации json_fixing_parser;\n",
    "        embedding_model (str): наименование модели эмбеддингов, использующаяся для поиска в RAG;\n",
    "        vectorstore_data (List[Dict[str, Any]]): данные для инициализации faiss vector_store. Каждый элемент списка должен иметь\n",
    "                                                 ключи (problem, title, category, attributes).\n",
    "        k (int, optional): максимальное количество примеров во few-shot в RAG. Defaults to 5.\n",
    "        score_threshold (float, optional): минимальный cosine similarity score для документа полученного из векторного хранилища для few-shot. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        Runnable: Цепочка с RAG.\n",
    "    \"\"\"\n",
    "    # Создаем векторную базу\n",
    "    docs = [\n",
    "        Document(\n",
    "            page_content=sku['problem'],\n",
    "            metadata={\n",
    "                'title': sku['title'], \n",
    "                'category': sku['category'],  \n",
    "                'attributes': sku.get('attributes', ''),\n",
    "            }) for sku in vectorstore_data\n",
    "    ]\n",
    "    vstore, vsearch, vadd = get_vector_store(docs, model_name=embedding_model)\n",
    "\n",
    "    # Создаем промпты для модели\n",
    "    prompt_template = create_model_prompts(system_prompt, user_prompt)\n",
    "\n",
    "    llm = ChatVertexAI(**llm_params)\n",
    "\n",
    "    # Создаем JsonFixingParser\n",
    "    json_fixing_parser = create_json_fixing_parser(\n",
    "        llm_params,\n",
    "        json_input_variables=params_json_fixing_parser.json_input_variables,\n",
    "        json_fixing_template=params_json_fixing_parser.json_fixing_template,\n",
    "        max_retries=params_json_fixing_parser.max_retries\n",
    "    )\n",
    "\n",
    "    embedder = SentenceTransformer('cointegrated/LaBSE-en-ru')\n",
    "    chain = (\n",
    "        # Подцепочка, которая делает запрос к векторной базе данных\n",
    "        RunnableMap({\n",
    "            'examples': itemgetter('problem') | (RunnableLambda(lambda x: vsearch(x, k=k, score_threshold=score_threshold)) |\n",
    "                                                RunnableLambda(lambda results: [(score, doc.model_dump()) for (doc,score) in results])), # производим поиск в векторной базе\n",
    "            'problem': itemgetter('problem'),  # сохраняем описание товара для дальнейшей передачи в промпт\n",
    "            'service_words': itemgetter('service_words')\n",
    "        }) |\n",
    "        RunnableMap({\n",
    "            'examples': itemgetter('examples'), # производим поиск в векторной базе\n",
    "            'problem': itemgetter('problem'),  # сохраняем описание товара для дальнейшей передачи в промпт\n",
    "            'service_words': itemgetter('service_words')\n",
    "        }) |\n",
    "        # Подцепочка, которая делает запрос к модели на основе информации из векторной базы данных\n",
    "        RunnableMap({\n",
    "            'examples': itemgetter('examples'),\n",
    "            'problem': itemgetter('problem'),  # сохраняем описание товара для дальнейшей передачи в промпт\n",
    "            'llm': RunnableMap({\n",
    "                'examples': itemgetter('examples') | RunnableLambda(prepare_retriever_results_to_prompt),\n",
    "                'problem': itemgetter('problem'),\n",
    "            }) | prompt_template | llm | json_fixing_parser\n",
    "        })\n",
    "    )\n",
    "\n",
    "\n",
    "    return chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(**llm_params)\n",
    "\n",
    "llm.invoke(\"Привет!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Request('GET', 'https://custom-servers.t1v.scibox.tech/label-studio/30/api/tasks/?project=3&page=1')>\n",
      "https://custom-servers.t1v.scibox.tech/label-studio/30/api/tasks/?project=3&page=1\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb Ячейка 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mast\u001b[39;00m \u001b[39mimport\u001b[39;00m literal_eval\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ls_client \u001b[39m=\u001b[39m LabelStudio(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     api_key\u001b[39m=\u001b[39mLS_API_KEY,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     base_url\u001b[39m=\u001b[39mLABEL_STUDIO_URL\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m tasks \u001b[39m=\u001b[39m ls_client\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mlist(project\u001b[39m=\u001b[39;49mRAG_DATA_PROJECT_ID)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m rows_for_validations \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/olegradaev/Projects/price-monitoring/notebooks/test_vertexai.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m tqdm(tasks):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/label_studio_sdk/tasks/client_ext.py:8\u001b[0m, in \u001b[0;36mTasksClientExt.list\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SyncPagerExt[T]:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m SyncPagerExt\u001b[39m.\u001b[39mfrom_sync_pager(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlist(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/label_studio_sdk/tasks/client.py:209\u001b[0m, in \u001b[0;36mTasksClient.list\u001b[0;34m(self, page, page_size, view, project, resolve_uri, fields, review, include, query, request_options)\u001b[0m\n\u001b[1;32m    192\u001b[0m _response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_wrapper\u001b[39m.\u001b[39mhttpx_client\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    193\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mapi/tasks/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     request_options\u001b[39m=\u001b[39mrequest_options,\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m _response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 209\u001b[0m     _parsed_response \u001b[39m=\u001b[39m pydantic_v1\u001b[39m.\u001b[39mparse_obj_as(TasksListResponse, _response\u001b[39m.\u001b[39;49mjson())  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     _has_next \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     _get_next \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist(\n\u001b[1;32m    212\u001b[0m         page\u001b[39m=\u001b[39mpage \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    213\u001b[0m         page_size\u001b[39m=\u001b[39mpage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m         request_options\u001b[39m=\u001b[39mrequest_options,\n\u001b[1;32m    222\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_models.py:764\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjson\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: typing\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 764\u001b[0m     \u001b[39mreturn\u001b[39;00m jsonlib\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontent, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# загрузим данные из LSs\n",
    "# чтение размеченных данных из LS\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "from ast import literal_eval\n",
    "\n",
    "ls_client = LabelStudio(\n",
    "    api_key=LS_API_KEY,\n",
    "    base_url=LABEL_STUDIO_URL\n",
    ")\n",
    "tasks = ls_client.tasks.list(project=RAG_DATA_PROJECT_ID)\n",
    "rows_for_validations = []\n",
    "for item in tqdm(tasks):\n",
    "    single_annotation = dict()\n",
    "    single_annotation['problem'] = item.data['problem']\n",
    "    single_annotation['lead_time'] = item.avg_lead_time\n",
    "    single_annotation['id'] = item.id\n",
    "    if single_annotation['id'] == 11542:\n",
    "        print(11542, len(full_annotation))\n",
    "        # print(item.annotations[0])\n",
    "    for full_annotation in item.annotations[-1]['result']:\n",
    "        # атрибуты требуют доп. обработки для устранения escate-символов\n",
    "        if full_annotation['type'] == 'choices':\n",
    "            continue\n",
    "        if full_annotation['from_name'] == 'comment_attrs' and single_annotation['id'] == 11542:\n",
    "            print(full_annotation)\n",
    "        single_annotation[full_annotation['from_name']] = \\\n",
    "            json.loads(convert_attrs_string2dict(full_annotation['value']['text'][-1])) \\\n",
    "                if full_annotation['from_name'] == 'comment_attrs' else full_annotation['value']['text'][-1]\n",
    "    rows_for_validations.append(single_annotation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Промпты \n",
    "\n",
    "system_prompt = '''Question: Extract the following information from the given name. Ensure that the output is a valid JSON and follows the structure strictly:\n",
    "    1) Service or product? (1 for service, 0 for product)\n",
    "    2) Basic name (extract the core name of the product or service, excluding any additional descriptive words, characteristics, or attributes. Ensure that the basic name provides sufficient detail to clearly identify the item, but avoid duplicating information such as size, quantity, or material if it is repeated elsewhere in the attributes. **Importantly, exclude any articles or alphanumeric codes, such as SKUs, from the basic name.** If the original string contains adjectives that give a clearer understanding of the product or service, include them in the basic name. The goal is to capture a name that can stand alone and be easily recognized.)\n",
    "    3) Article (identify any alphanumeric string that may represent an article, if present in the name. Ensure that the article is not just a combination of letters and numbers that represent other attributes, such as size, volume, weight, or quantity (e.g., \"10мл\", \"100г\", \"1л\" should be ignored). An article typically consists of a unique identifier, such as a SKU or product code, that distinguishes the product. If the article cannot be determined or is ambiguous, leave it empty.)\n",
    "    4) Category. Select category basing on example categories;\n",
    "    5) Other attributes as key-value pairs (extract all additional descriptive words, characteristics, or attributes from the original name and assign them with meaningful keys. **The values of the keys can represent single values or lists of values**. Ensure that the keys in the attributes are correctly formed, and the values are the attributes taken from the original name, not indicated as True or False.)\n",
    "\n",
    "- Ensure that the keys in the attributes are correctly formed, following these rules:\n",
    "    - Write all keys and values in the **nominative case**.\n",
    "    - Expand abbreviations wherever they appear in the text.\n",
    "    - Use **capitalized letters** for the names of attributes and their values.\n",
    "    - Numerical values of attributes should be separated by spaces.\n",
    "\n",
    "**Knowledge Base Context:**\n",
    "The following example has been retrieved from the knowledge base to provide additional context:\n",
    "{examples}\n",
    "\n",
    "**Important:** Process only the provided name and do not add any other names or identifiers. Treat the name as a single independent entity.\n",
    "\n",
    "If any field cannot be determined, leave it empty.\n",
    "\n",
    "The output must strictly adhere to the following format:\n",
    "{{% raw %}}\n",
    "{{{{\n",
    "    \"id_1\": {{{{\n",
    "    \"услуга\": 1, \n",
    "    \"базовое_наименование\": \"\", \n",
    "    \"артикул\": \"\", \n",
    "    \"категория\": \"\", \n",
    "    \"атрибуты\": {{{{\n",
    "    }}}}\n",
    "}}}}\n",
    "}}}}\n",
    "{{% endraw %}}\n",
    "Ensure that:\n",
    "- No fields are missing.\n",
    "= Expand abbreviations wherever they appear in the text, if their meaning can be determined.\n",
    "- If a value cannot be determined, leave it as an empty string or an empty object.\n",
    "- Most importantly, try to determine the most appropriate category for the product or service based on its meaning.\n",
    "- **Allow attribute values to be single values or lists of values where applicable.**\n",
    "\n",
    "**Do not generate any text after the JSON output.**\n",
    "'''\n",
    "user_prompt = '''Help me with next problem: {problem}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
